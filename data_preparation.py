#Authored by Julius Välja

import pandas as pd
from sklearn.model_selection import train_test_split

data_df = pd.read_csv("full_results.csv")
question_df = pd.read_csv("survey_questions.csv")

data_df = data_df.drop(columns=['submitdate. Date submitted',
       'lastpage. Last page',
       'startlanguage. Start language',
       'seed. Seed',
       'refurl. Referrer URL',
       'G33Q250. Please enter your Prolific ID:',
       'G02Q251. By starting the survey, you consent to participate in the research described above and allow the use of the anonymous data for educational and research purposes. Participation in the study is entirely voluntary. If for any reason you no longer wish to participate in the study, you may exit the survey before submitting the responses.',
       'G04Q11. How old are you?     ',
       'G02Q18. Please enter your citizenship:',
       'G04Q12. What is your highest completed level of education?',
       'G04Q13. What is your level of English proficiency?',
       'G04Q14. Do you have any previous experience in the field of machine learning?',
       'G04Q16. Do you have any previous experience with counterfactual explanation frameworks or causality frameworks?',
       'G02Q17. Do you have a medical background?',
       'G02Q08. From 1 (not at all) to 6 (perfectly), how well did you understand the metrics:'])


def promptGPT(s,i, answer):
  d = {0:"Satisfaction", 1:"Feasibility", 2:"Consistency", 3:"Completeness", 4:"Trust", 5:"Understandability", 6:"Fairness", 7:"Complexity"}
  return {"messages": [{"role": "system", "content": """You are evaluating counterfactual explanations generated by AI.  Counterfactual explanations explain what parameters of a situation should have been different for the outcome to have been different. You are not expected to provide reasoning or explanation and should answer with the appropriate value from the set ["low", "medium", "high"].""" + match2(i)},
                       {"role":"user", "content": s + match(i)},
                       {"role":"assistant", "content":  answer }]}


#Mapping values to string. Assumes that all values are scaled 0 to 5
def func(value):
  if(value<2):
    return "low"
  if(value<3):
    return "medium"
  return "high"


#For using specific participants
dataset = pd.DataFrame(columns=["prompt", "type", "answer_A","answer_B","answer_C","answer_D"])



#For using average values
dataset = pd.DataFrame(columns=["prompt", "type", "answer"])
means = data_df.mean().drop(["id. Response ID","Mean"])

for i in range(240):
    
  #For using average values for each question
  if(i%8==7):
    dataset.loc[i] = [question_df.iloc[i//8].Question, str(int(round(means[i]*1.25+2.5))), i%8]
    continue
  dataset.loc[i] = [question_df.iloc[i//8].Question, str(int(round(means[i]-1))),i%8]
  
  #To generate dataset for GPT-4
  if(i%8==7):
    dataset.loc[i] = [promptGPT(question_df.iloc[i//8].Question,i%8,func(means[i]*1.25+2.5))]
    continue
  dataset.loc[i] = [promptGPT(question_df.iloc[i//8].Question,i%8,func(means[i]-1))]
  
  #To use specific participants answers
  if(i%8==7):
    dataset.loc[i] = [question_df.iloc[i//8].Question, i%8, func(data_df.drop(columns=["id. Response ID", "Mean"]).iloc[8][i]*1.25+2.5),func(data_df.drop(columns=["id. Response ID", "Mean"]).iloc[17][i]*1.25+2.5),func(data_df.drop(columns=["id. Response ID", "Mean"]).iloc[19][i]*1.25+2.5), func(data_df.drop(columns=["id. Response ID", "Mean"]).iloc[85][i]*1.25+2.5)]
    continue
  dataset.loc[i] = [question_df.iloc[i//8].Question, i%8, func(data_df.drop(columns=["id. Response ID", "Mean"]).iloc[8][i]-1),func(data_df.drop(columns=["id. Response ID", "Mean"]).iloc[17][i]-1),func(data_df.drop(columns=["id. Response ID", "Mean"]).iloc[19][i]-1), func(data_df.drop(columns=["id. Response ID", "Mean"]).iloc[85][i]-1)]
  

#To split dataset into training and testing data. Random_state is chosen so that all metrics have at least one example of "high", "medium" and "low" values.
Tr0, Ts0 = train_test_split(dataset, train_size=0.8,stratify=dataset.type, random_state=16006)

#Saving the datasets
Tr0.to_csv("train_LM.csv")
Ts0.to_csv("test_LM.csv")

#Saving GPT-4 dataset
Tr0.prompt.to_json("gpt_train.json", orient="records", lines=True)
Ts0.prompt.to_json("gpt_test.json", orient="records", lines=True)
